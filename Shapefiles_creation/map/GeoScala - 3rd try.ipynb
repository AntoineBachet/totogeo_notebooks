{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages = [\"harsha2010:magellan:1.0.5-s_2.11\"]\n",
    "launcher.conf.set(\"spark.ui.port\", \"4041\")\n",
    "launcher.conf.set(\"spark.ui.reverseProxyUrl\", \"https://gisui.totosearch.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://172.17.0.5:4042\n",
       "SparkContext available as 'sc' (version = 2.2.3, master = local[*], app id = local-1554325728084)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SQLContext\n",
       "sqlCtx: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@26315fd7\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "val sqlCtx = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import magellan.{Point, Polygon}\n",
       "import org.apache.spark.sql.magellan.dsl.expressions._\n",
       "import org.apache.spark.sql.types._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import magellan.{Point, Polygon}\n",
    "import org.apache.spark.sql.magellan.dsl.expressions._\n",
    "import org.apache.spark.sql.types._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the shapefile containing continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             polygon|\n",
      "+--------------------+\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "|magellan.Polygon@...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [point: point, polyline: polyline ... 3 more fields]\n",
       "polygons: org.apache.spark.sql.DataFrame = [polygon: polygon]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sqlCtx.read.format(\"magellan\").load(\"/tf/Team 6 - Project/Creating shapefiles/Grid shapefiles/\")\n",
    "val polygons = df.select(\"polygon\")\n",
    "\n",
    "polygons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extractDouble: (expectedNumber: Any)Option[Double]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractDouble(expectedNumber: Any): Option[Double] = expectedNumber match {\n",
    "    case d: Double => Some(d)\n",
    "    case i: Int => Some(i.toDouble)\n",
    "    case l: Long => Some(l.toDouble)\n",
    "    case s: String => scala.util.Try(s.trim.toDouble).toOption\n",
    "    case _ => None\n",
    "  } \n",
    "\n",
    "for (i <- 1 to 100){\n",
    "    var df_points = spark.read.\n",
    "    format(\"csv\").\n",
    "    option(\"header\", \"true\").\n",
    "    load(s\"/tf/Team 6 - Project/Creating shapefiles/Grid shapefiles/Partial_grids/Grid_$i\")\n",
    "    \n",
    "    var grid = df_points.collect()\n",
    "\n",
    "    var points_grid = sc.parallelize(grid.map(x => (extractDouble(x(1)),extractDouble(x(0)))).collect{case (Some(i), Some(j)) => (i,j)}.toSeq).toDF(\"Longitude\", \"Latitude\").select(point($\"Longitude\", $\"Latitude\").as(\"point\"))\n",
    "\n",
    "    var cont_points = points_grid.join(polygons).\n",
    "    where($\"point\" within $\"polygon\").\n",
    "    select(\"point\").collect().\n",
    "    map(x => x(0).toString).\n",
    "    map(x => x.split('(')(1).split(')')(0).split(',')).\n",
    "    map(y => (y(0).toDouble, y(1).toDouble)).toSeq.\n",
    "    toDF(\"Longitude\", \"Latitude\").\n",
    "    write.format(\"csv\").save(s\"/tf/Team 6 - Project/Creating shapefiles/Grid shapefiles/Partial_grids/Grid_$i/grid\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
